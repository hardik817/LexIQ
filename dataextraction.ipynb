{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd4ad1d",
   "metadata": {},
   "source": [
    "Perform All the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73637902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import json\n",
    "import cohere\n",
    "import gradio as gr\n",
    "from keybert import KeyBERT\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34925c6",
   "metadata": {},
   "source": [
    "Load the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8df511fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"coastalcph/lex_glue\", \"case_hold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b82594",
   "metadata": {},
   "source": [
    "About The Dataset:-\n",
    "\n",
    "Inspired by the recent widespread use of the GLUE multi-task benchmark NLP dataset (Wang et al., 2018), the subsequent more difficult SuperGLUE (Wang et al., 2019), other previous multi-task NLP benchmarks (Conneau and Kiela, 2018; McCann et al., 2018), and similar initiatives in other domains (Peng et al., 2019), we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a benchmark dataset to evaluate the performance of NLP methods in legal tasks. LexGLUE is based on seven existing legal NLP datasets, selected using criteria largely from SuperGLUE.\n",
    "\n",
    "As in GLUE and SuperGLUE (Wang et al., 2019b,a), one of our goals is to push towards generic (or ‘foundation’) models that can cope with multiple NLP tasks, in our case legal NLP tasks possibly with limited task-specific fine-tuning. Another goal is to provide a convenient and informative entry point for NLP researchers and practitioners wishing to explore or develop methods for legalNLP. Having these goals in mind, the datasets we include in LexGLUE and the tasks they address have been simplified in several ways to make it easier for newcomers and generic models to address all tasks.\n",
    "\n",
    "LexGLUE benchmark is accompanied by experimental infrastructure that relies on Hugging Face Transformers library and resides at: https://github.com/coastalcph/lex-glue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181f6329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'endings', 'label'],\n",
       "        num_rows: 45000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['context', 'endings', 'label'],\n",
       "        num_rows: 3600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['context', 'endings', 'label'],\n",
       "        num_rows: 3900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125ad51",
   "metadata": {},
   "source": [
    "Load the environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34678a5",
   "metadata": {},
   "source": [
    "Merge test,train,split to provide all the information to the rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d34f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1=[]\n",
    "for row in ds['train']:\n",
    "    ds1.append(row)\n",
    "for row in ds['validation']:\n",
    "    ds1.append(row)\n",
    "for row in ds['test']:\n",
    "    ds1.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba7b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "claude_api_key = os.getenv('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4aa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geminimodel=OpenAI(api_key=google_api_key,\n",
    "                  base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=claude_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408b4bb",
   "metadata": {},
   "source": [
    "Analysing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a56773f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drapeau’s cohorts, the cohort would be a “victim” of making the bomb. Further, firebombs are inherently dangerous. There is no peaceful purpose for making a bomb. Felony offenses that involve explosives qualify as “violent crimes” for purposes of enhancing the sentences of career offenders. See 18 U.S.C. § 924(e)(2)(B)(ii) (defining a “violent felony” as: “any crime punishable by imprisonment for a term exceeding one year ... that ... involves use of explosives”). Courts have found possession of a'bomb to be a crime of violence based on the lack of a nonviolent purpose for a bomb and the fact that, by its very nature, there is a substantial risk that the bomb would be used against the person or property of another. See United States v. Newman, 125 F.3d 863 (10th Cir.1997) (unpublished) (<HOLDING>); United States v. Dodge, 846 F.Supp. 181,\n",
      "['holding that possession of a pipe bomb is a crime of violence for purposes of 18 usc  3142f1', 'holding that bank robbery by force and violence or intimidation under 18 usc  2113a is a crime of violence', 'holding that sexual assault of a child qualified as crime of violence under 18 usc  16', 'holding for the purposes of 18 usc  924e that being a felon in possession of a firearm is not a violent felony as defined in 18 usc  924e2b', 'holding that a court must only look to the statutory definition not the underlying circumstances of the crime to determine whether a given offense is by its nature a crime of violence for purposes of 18 usc  16']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(ds['train'][0]['context'])\n",
    "print(ds['train'][0]['endings'])\n",
    "print(ds['train'][0]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f022ac2",
   "metadata": {},
   "source": [
    "Do not reccomend this way as the metadata only contains label which are not sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "sum=0\n",
    "for row in ds1:\n",
    "    full_text = row['context'] + \" \" + \" \".join(row['endings'])\n",
    "    docs.append(Document(page_content=full_text.strip(), metadata={\"class\":row['label']}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a28bf",
   "metadata": {},
   "source": [
    "Trying a keybert model in order to create tags for the page_content.But the keybert often loses context and registers non-violence as violence due to the use of stopwords. This would lead miss-classification and vectorization of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad277355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name nlpaueb/legal-bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "legal_bert_model = SentenceTransformer(\"nlpaueb/legal-bert-base-uncased\")\n",
    "\n",
    "\n",
    "kw_model = KeyBERT(model=legal_bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc446254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legal_tags(text, top_n=5, ngram_range=(1, 3)):\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        text,\n",
    "        keyphrase_ngram_range=ngram_range,\n",
    "        stop_words='english',\n",
    "        top_n=top_n,\n",
    "        use_mmr=True,           # optional: promotes diversity\n",
    "        diversity=0.5           # optional: 0.0 = similar, 1.0 = diverse\n",
    "    )\n",
    "    return [kw for kw, _ in keywords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce8808",
   "metadata": {},
   "source": [
    "Using LLM like claude/gemini to create tags for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19ec453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt3=\"\"\"You are a legal assistant. Extract 3 to 5 concise legal issue tags from the following case text. Pay close attention to negations and context. Return only a comma-separated list of tags.Give only tags strictly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c69b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_legal_tags(text):\n",
    "    user_query=\"Extract 3-5 concise legal tags from case text.Only give tags\"+text\n",
    "    response = client.messages.create(\n",
    "    model=\"claude-3-5-haiku-20241022\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.7,\n",
    "    system=system_prompt3,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    plain_text_response = ''.join(block.text for block in response.content)\n",
    "\n",
    "    return plain_text_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0abe94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags(text):\n",
    "    tags = generate_legal_tags(text)\n",
    "    tags=tags.split(',')\n",
    "    tags = [tag.strip() for tag in tags if tag.strip()]  # Clean up whitespace\n",
    "    return tags\n",
    "# Output example: ['Eighth Amendment', 'life sentence', 'non-violent drug offense', 'Harmelin v. Michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba99b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for row in ds1:\n",
    "    full_text = row['context'] + \" \" + \" \".join(row['endings'])\n",
    "    tags= create_tags(full_text)\n",
    "    docs.append(Document(page_content=full_text.strip(), metadata={\"class\":row['label'],\"tags\": tags}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2a8d5",
   "metadata": {},
   "source": [
    "Store the new dataset with tags locally to use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_list5.txt', 'w') as f:\n",
    "    for doc in docs:\n",
    "        json.dump({'metadata': doc.metadata, 'page_content': doc.page_content}, f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
